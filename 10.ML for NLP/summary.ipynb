{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML for NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing\n",
    "\n",
    "### Tokenization\n",
    "Tokenization is the process of breaking down text into smaller units such as sentences, words, or subwords. These units are called tokens.\n",
    "\n",
    "- **Corpus**: A collection of text data used for analysis and training machine learning models.\n",
    "- **Documents**: Individual pieces of text within the corpus, such as articles, paragraphs, or files.\n",
    "- **Vocabulary**: The set of unique tokens present in a corpus after tokenization.\n",
    "- **Words**: The smallest meaningful units in tokenization, typically split by spaces or punctuation.\n",
    "\n",
    "**Advantages**:\n",
    "- Simplifies text into manageable units for analysis.\n",
    "- Enables further preprocessing steps like stemming, lemmatization, and vectorization.\n",
    "- Supports sentence, word, or subword-level processing for different use cases.\n",
    "\n",
    "**Limitations**:\n",
    "- Can split words incorrectly (e.g., hyphenated words or abbreviations).\n",
    "- Does not consider the semantic context of tokens.\n",
    "- Fails to handle complex languages with compound words or agglutinative structures effectively.\n",
    "\n",
    "---\n",
    "\n",
    "### Stemming\n",
    "Stemming is the process of reducing words to their root or base form. It removes affixes like suffixes and prefixes. For example:\n",
    "- \"running\" → \"run\"\n",
    "- \"flies\" → \"fli\"\n",
    "\n",
    "Common algorithms include Porter Stemmer and Snowball Stemmer.\n",
    "\n",
    "**Advantages**:\n",
    "- Reduces dimensionality by grouping similar words.\n",
    "- Computationally faster than lemmatization.\n",
    "\n",
    "**Limitations**:\n",
    "- May produce non-meaningful root words (e.g., \"flies\" → \"fli\").\n",
    "- Loses linguistic meaning and context.\n",
    "- Over-stemming or under-stemming can occur, leading to inaccurate grouping.\n",
    "\n",
    "---\n",
    "\n",
    "### Lemmatization\n",
    "Lemmatization also reduces words to their base or dictionary form, but it considers the context and meaning of the word. For example:\n",
    "- \"running\" → \"run\"\n",
    "- \"better\" → \"good\"\n",
    "\n",
    "Unlike stemming, lemmatization uses vocabulary and morphological analysis.\n",
    "\n",
    "**Advantages**:\n",
    "- Produces meaningful and context-aware base forms.\n",
    "- Improves accuracy in downstream tasks like sentiment analysis or machine translation.\n",
    "\n",
    "**Limitations**:\n",
    "- Computationally intensive due to reliance on vocabulary and context analysis.\n",
    "- Requires language-specific resources such as dictionaries and part-of-speech tagging.\n",
    "\n",
    "---\n",
    "\n",
    "### Stop Words\n",
    "Stop words are common words in a language that are often removed during text preprocessing because they do not carry significant meaning. Examples include:\n",
    "- \"the\"\n",
    "- \"is\"\n",
    "- \"and\"\n",
    "\n",
    "**Advantages**:\n",
    "- Reduces noise in the data.\n",
    "- Improves model efficiency by focusing on meaningful words.\n",
    "- Decreases vocabulary size, which can speed up processing.\n",
    "\n",
    "**Limitations**:\n",
    "- Removing stop words may discard contextually important words, depending on the task (e.g., in sentiment analysis, words like \"not\" are critical).\n",
    "- Requires language-specific stop word lists.\n",
    "\n",
    "---\n",
    "\n",
    "### Part of Speech (PoS) Tagging\n",
    "PoS tagging assigns a part of speech (e.g., noun, verb, adjective) to each token in the text. It is used to understand the grammatical structure and context of the text. Example:\n",
    "- \"She is running.\" → \n",
    "  - She (pronoun)\n",
    "  - is (verb)\n",
    "  - running (verb)\n",
    "\n",
    "**Advantages**:\n",
    "- Provides grammatical insights that enhance tasks like parsing, NER, and dependency analysis.\n",
    "- Supports feature extraction for machine learning models.\n",
    "\n",
    "**Limitations**:\n",
    "- Requires accurate models and labeled data for tagging.\n",
    "- Errors in tagging can propagate to downstream tasks.\n",
    "- Ambiguous words (e.g., \"run\" as a verb or noun) can be misclassified.\n",
    "\n",
    "---\n",
    "\n",
    "### Named Entity Recognition (NER)\n",
    "NER identifies and categorizes named entities in text into predefined categories, such as:\n",
    "- **Persons**: \"John Doe\"\n",
    "- **Organizations**: \"Google\"\n",
    "- **Locations**: \"Paris\"\n",
    "- **Dates**: \"January 1st, 2024\"\n",
    "\n",
    "**Advantages**:\n",
    "- Extracts structured information from unstructured text.\n",
    "- Useful for real-world applications like information retrieval, chatbots, and summarization.\n",
    "- Simplifies text by focusing on relevant entities.\n",
    "\n",
    "**Limitations**:\n",
    "- Performance depends on the quality of training data and the domain (e.g., general vs. medical texts).\n",
    "- Struggles with out-of-vocabulary entities or informal text.\n",
    "- Errors in recognizing entities can reduce system effectiveness in downstream tasks.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
